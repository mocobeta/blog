+++
title = "DeepSeek-R1のビジュアルガイドを読んだ"
date = "2025-02-24"

[taxonomies]
categories = ["Posts"]
tags = ["til", "llm", "deepseek"]
+++


[A Visual Guide to Reasoning LLMs - A Visual Guide to Reasoning LLMs](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-reasoning-llms)

[The Illustrated DeepSeek-R1 - Language Models & Co.](https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1)

OpenAI o3やDeepSeek-R1で話題の "Reasoning" LLMモデルに関して，「Chain-of-Thoughtを勝手に実行してくれるつよいモデル」というものすごく雑なメンタルモデルだったのが，だいぶ整理された。このくらいイメージがつくと，オリジナルの論文にも挑戦できそう。

個人的には，最初にあげたMaarten Grootendorstの解説のほうがわかりやすかった。

上記2つの記事の著者，Jay AlammarとMaarten Grootendorstによる

[Hands-On Large Language Models (2024年, O'Reilly)](https://www.llm-book.com/)

も気になっている。

私がJay Allammarを初めて知ったのは，

[The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)

だったのだけど，このビジュアライズ解説記事は本当に名作だと思う。